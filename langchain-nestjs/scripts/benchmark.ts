import { ChatOllama } from "@langchain/ollama";
import { HumanMessage } from "@langchain/core/messages";

const MODELS = [
  "llama3:8b-instruct-q4_0",
  "llama3:8b-instruct-q6_K",
];

const TEST_PROMPT = `You are a ReAct agent. Answer the question using the following format:
Thought: [your reasoning]
Action: calculator
Action Input: [math expression]

Question: –°–∫–æ–ª—å–∫–æ –±—É–¥–µ—Ç (125 * 4) + 50?`;

async function runBenchmark() {
  console.log("üöÄ –ù–∞—á–∏–Ω–∞–µ–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π...\n");
  const results = [];

  for (const modelName of MODELS) {
    console.log(`üì° –¢–µ—Å—Ç–∏—Ä—É–µ–º: ${modelName}...`);
    
    const llm = new ChatOllama({
      model: modelName,
      temperature: 0,
    });

    const start = performance.now();
    try {
      const response = await llm.invoke([new HumanMessage(TEST_PROMPT)]);
      const end = performance.now();
      
      const duration = ((end - start) / 1000).toFixed(2);
      
      results.push({
        model: modelName,
        time: `${duration}s`,
        output: response.content.toString().substring(0, 1900).replace(/\n/g, " ") + "..."
      });
    } catch (e) {
      results.push({ model: modelName, time: "ERROR", output: "–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å" });
    }
  }

  console.log("\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –°–†–ê–í–ù–ï–ù–ò–Ø:");
  console.table(results);
}

runBenchmark().catch(console.error);

// TLfMdAQEY2iDWFsMdYeoVHxWAYbbYLghEM

// TLfMdAQEY2iDWFsMdYeoVHxWAYbbYLghEM